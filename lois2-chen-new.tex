%%「論文」，「レター」，「レター（C分冊）」，「技術研究報告」などのテンプレート
%% v3.3 [2020/06/02]

\documentclass[technicalreport]{ieicej}
\usepackage[dvipdfmx]{graphicx,xcolor}
\usepackage{float}
\usepackage[fleqn]{amsmath}
\usepackage{newtxtext}% 英数字フォントの設定を変更しないでください
\usepackage[varg]{newtxmath}% % 英数字フォントの設定を変更しないでください
\usepackage{latexsym}
\usepackage{listings}
\usepackage{xurl}
\usepackage{fancyvrb}
\usepackage{multirow}
\usepackage{array}
\usepackage[section]{placeins} % make sure all fig and table do not go to other sections
\usepackage{stfloats} % somehow avoid the possible blank page by fig or table
% \usepackage[normalem]{ulem}
% \useunder{\uline}{\ul}{}
%\usepackage{amssymb}


\renewcommand{\refname}{References} % To get english reference section heading
\renewcommand{\figurename}{Fig.} % To get english figure heading
\renewcommand{\tablename}{Table} % To get english table heading
\renewcommand\UrlFont{\rmfamily} % Fix url font

\lstset{%
    language={Python},
    basicstyle={\small},%
    identifierstyle={\small},%
    commentstyle={\small\itshape},%
    keywordstyle={\small\bfseries},%
    ndkeywordstyle={\small},%
    stringstyle={\small\ttfamily},
    frame={tb},
    breaklines=true,
    columns=[l]{fullflexible},%
    numbers=left,%
    xrightmargin=0zw,%
    xleftmargin=3zw,%
    numberstyle={\scriptsize},%
    stepnumber=1,
    showstringspaces=false,%
    numbersep=1zw,%
    lineskip=-0.5ex,%
    %moredelim=[is][\underbar]{_}{_},%
    keepspaces=true,%
    %escapechar=\@
}

% \jtitle{タイトル}
% \jsubtitle{}
\etitle{A Study of Product Identification System Using Optical Character Recognition}
% \esubtitle{}
\authorlist{%
 \authorentry[chin-shiji@s.okayama-u.ac.jp]{陳 仕璽}{Shixi Chen}{okayama}
 \authorentry[funabiki@okayama-u.ac.jp]{舩曵 信生}{Nobuo Funabiki}{okayama}
 \authorentry[phvf8tn3@s.okayama-u.ac.jp]{坂上 正規}{Masaki Sakagami}{okayama}
 \authorentry[toshida.takashi@astrolab.co.jp]{土信田 高}{Takashi Toshida}{astrolab}
 \authorentry[suga@astrolab.co.jp]{菅 恒平}{Kohei Suga}{astrolab}
% \authorentry[メールアドレス]{和文著者名}{英文著者名}{所属ラベル}
}
\affiliate[okayama]{}
{Okayama University\hskip1em
Tsushimanaka 3-1-1, Okayama, 700--8530, Japan}
\affiliate[astrolab]{}
{Astrolab \hskip1em
Otemachi 2-6-2, Chiyoda, Tokyo, 100-0004, Japan}
%\affiliate[所属ラベル]{和文勤務先\\ 連絡先住所}{英文勤務先\\ 英文連絡先住所}
\jalcdoi{???????????}% ← このままにしておいてください

\begin{document}
% \begin{jabstract}
% %和文あらまし
% \end{jabstract}
% \begin{jkeyword}
% %和文キーワード
% \end{jkeyword}

\begin{eabstract}
    %background
    Recently, the {\em optical character recognition (OCR)} technology has been remarkably progressed due to the advancements of {\em deep learning techniques}. Besides, smartphones equipped with cameras have broadly spread among people around the world. As a result, the product identification from the product label photo using OCR becomes possible as the quick way to identify the product.
    %problem to be solved
    However, the accuracy of OCR is still not $100\%$. Some characters are incorrectly recognized or missing in the recognition result, which must be considered for use. 
    %contribution
    In this study, we propose a {\em product identification system} applying OCR of the label photo taken by a smart phone. The {\em fuzzy search} is adopted to improve the accuracy by finding the best-matching record in the database for the possibly incorrect key by OCR. Since this search takes inadmissibly long time when the database has a lot of records, we also propose the speedup method by limiting the matching records. 
    %evaluation
    For evaluations, we apply the proposal to $396$ label photos. The results show that the CPU time is $15.241sec$ by the naïve search, and $0.984sec$ by the speedup one that limits the number of matching records into $0.24\%$ of the naïve one, where the record hit rate is slightly reduced from $91.16\%$ to $90.91\%$.
\end{eabstract}

\begin{ekeyword}
product identification, OCR, fuzzy search, regular expression, partial word matching
\end{ekeyword}
\maketitle

%+++++++++++++++++++++++++++++++++++++++++++++++
\section{Introduction}
    %background
    Recently, the {\em optical character recognition (OCR)} technology has been remarkably progressed as the advancements of {\em deep learning techniques}, and resulted in the high recognition rate. Besides, smartphones equipped with cameras have broadly spread among people around the world. As a result, the product identification from the product label photo using OCR becomes possible as the quick way to identify the product.

    %problem to be solved
    However, the character recognition rate of OCR is still not $100\%$. Some characters are incorrectly recognized or missing in the recognition result. Then, if a database is available where the correct characters or strings are stored at the record, the {\em fuzzy search} can be adopted to improve the accuracy by finding the best matching record with the recognition result by OCR. Unfortunately, this search will take inadmissibly long time if the database has a lot of records, because it spends much longer time to process one record. 

    %contribution
    In this study, we propose a {\em product identification system} that applies OCR of the label photo taken by a smart phone. The {\em fuzzy search} is adopted to improve the accuracy by finding the best-matching record in the database for the key string extracted by OCR. However, the fuzzy search takes inadmissibly long time when the database has a lot of records. It calculates the similarity distance between the key data and the stored data in each record. Therefore, we also propose the speedup method by limiting the matching records. 

    %speedup method
    The speedup method limits the matching records with the key that contain a part of the characters in the key. In this paper, the alphanumeric string of the key is divided into two halves, and the records containing either of the half string are extracted from the database. After that, the {\em fuzzy search} is applied to the extracted records only instead of the whole records. 

    %evaluation
    For evaluations, we collect $396$ photos of various product labels and their OCR results, and apply our proposal to them. The application results show that the naïve fuzzy search takes $15.241sec$ for the CPU time achieves $91.16\%$ correct rate. Then, the speedup method drastically reduces the CPU time to $0.984sec$ and slightly decreases the correct rate to $90.91\%$, where the number of matching records becomes 0.24\% of the original. The improvement of the correct rate will be in future studies.

    %contents
    The rest of this paper is organized as follows:
    Section~\ref{sec:preliminary} shows preliminary technologies to this study.
    Section~\ref{sec:proposal} presents the product identification system with the naïve logic.
    Section~\ref{sec:speedup} presents the speedup method for the {\em fuzzy search}.
    Section~\ref{sec:evaluation} shows the evaluation results.
    Finally, Section~\ref{sec:conclusion} concludes this paper with future works.

%+++++++++++++++++++++++++++++++++++++++++++++++
\section{Preliminary}
\label{sec:preliminary}
    In this section, we introduce preliminary technologies to our study in this paper.

    \subsection{Levenshtein Distance}
        The {\em Levenshtein distance} represents the string metric for measuring the difference between two sequences of strings \cite{fuzzywuzzy-guidence}. Informally, the {\em Levenshtein distance} between two words is given by the minimum number of single-character editions by either insertions, deletions, or substitutions that are required to change one word into another one, or the {\em mininum edit distace (MED)} \cite{fuzzywuzzy-guidence}-\cite{levenshtein}.         

        The {\em Levenshtein distance} between two strings $a$ and $b$, $lev(a, b)$, can be calculated recursively by:

        \begin{equation}
                \operatorname{lev}(a, b)=\left\{\begin{array}{ll}
                |a| & \text { if }|b|=0 \\
                |b| & \text { if }|a|=0 \\
                \operatorname{lev}(\operatorname{tail}(a), \operatorname{tail}(b)) & \text { if } a[0]=b[0] \\
                1+\min \left\{\begin{array}{l}
                \operatorname{lev}(\operatorname{tail}(a), b) \\
                \operatorname{lev}(a, \operatorname{tail}(b)) \\
                \operatorname{lev}(\operatorname{tail}(a), \operatorname{tail}(b))
                \end{array}\right. & \text { otherwise. }
                \end{array}\right.
        \end{equation}
        where $|x|$ represents the number of characters in the string $x$, $tail(x)$ is a string of all but the first character of string $x$, and $x[n]$ is the $n$th character of the string $x$, starting with character 0. Due to the recursive procedure, the calculation of the {\em Levenshtein distance} between two strings generally takes much longer time than the simple comparison of them.

    \subsection{FuzzyWuzzy}
        {\em FuzzyWuzzy} is the {\em Python} library to calculate the similarity between two alphanumeric strings or sequences by calculating the {\em Levenshtein distance}, relying on the {\em Difflib} module \cite{fuzzywuzzy}-\cite{fuzzywuzzy-git}. In this paper, we use the {\em simple ratio method} of {\em FuzzyWuzzy} to calculate the similarity between two strings that is described by an integer from 0 to 100. When two strings are exactly the same, the similarity is 100. When a five-character string is examined, the similarity against a string that has one different character is $80$. {\bf Command 1} illustrates the command operation example using {\em FuzzyWuzzy} to two five-character strings where only the fourth one is different.
     
        \begin{center}\bf Command 1\end{center}
        \begin{lstlisting}
>>> from fuzzywuzzy import fuzz
>>> fuzz.ratio("A1532", "A15B2")
80      \end{lstlisting}

    \subsection{Information on Product Label}
        The proposed system identifies the product using the information on the product label. As shown in Figure~\ref{fig:label-exp}, the label usually displays the company name, the product name, the product model number, and the production slot number. Among them, the {\em product model number} is used to identify the product in our system, because it is usually uniquely assigned to each product regardless of different companies. Therefore, the accurate recognition of the {\em product model number} becomes the goal of this study.

        \begin{figure}[t] 
            \begin{center}
            \includegraphics[width=0.48\textwidth]{figure/label-exp.png}
            \end{center}
            \caption{Example product label photo.}
            \label{fig:label-exp}
        \end{figure}


%+++++++++++++++++++++++++++++++++++++++++++++++
\section{Proposal of Product Identification System}
\label{sec:proposal}
    In this section, we propose a {\em product identification system} using OCR and a smartphone camera. To identify the product handily, this system obtains the label photo using a smart phone. Then, the product information is extracted by applying OCR to the photo. The {\em fuzzy search} is adopted to improve the accuracy by finding the best-matching record in the database for the possibly incorrect key by OCR. 

    \subsection{System Overview}
        Figure~\ref{fig:system} illustrates the overview of the proposed product identification system. As the system hardware, a {\em smartphone} is used to take a label photo of a target product, to upload the photo to the {\em server}, and to display the identification result to the user. Then, the {\em server} is adopted to run several programs including the web server for the user interface on the smartphone, the interface program to the OCR software, the database system, and the product identification program using {\em FuzzyWuzzy}. 

        \begin{figure}[t] 
            \begin{center}
            \includegraphics[width=0.48\textwidth]{figure/system.pdf}
            \end{center}
            \caption{System overview.}
            \label{fig:system}
        \end{figure}

    \subsection{System Usage Procedure}
        The usage procedure of the system is described as follows:

        \begin{enumerate}
            \item to take a photo of the product label using a smartphone and upload it to the server using the web browser,
            \item to recognize the characters on the label from the photo using an OCR software on the server,
            \item to extract a set of the candidate strings for the {\em product model number} from the recognized characters by using the {\em regular expression}, 
            \item to calculate the similarity between each candidate string and every records in the database,
            \item to select all the records that have the larger similarity than the given threshold, and display the corresponding product model numbers in descending order of the similarity to the user. 
        \end{enumerate}

        In the following subsections, the details of each step will be explained.

    \subsection{Label Photo by Smarphone}
    \label{sec:label-requirement}
        The user interface for taking the label photo of a product is implemented on a web browser such as Google Chrome with HTML and JavaScript programs. Figure~\ref{fig:homepage} illustrates the web page to take a label photo using a smartphone. By clicking the file selection button on the page, the camera application in the smartphone will be automatically called up.

        \begin{figure}[t] 
            \begin{center}
            \includegraphics[width=0.48\textwidth]{figure/homepage.png}
            \end{center}
            \caption{Web page for taking photo by smartphone.}
            \label{fig:homepage}
        \end{figure}

        \begin{figure}[t] 
            \begin{center}
            \includegraphics[width=0.35\textwidth]{figure/camera.png}
            \end{center}
            \caption{Smartphone interface after taking photo.}
            \label{fig:camera}
        \end{figure}

        Figure~\ref{fig:camera} shows the user interface on the smartphone after taking a photo. By clicking the “OK” button, the photo will be uploaded to the server. The photo must be taken from the front of the product label. The ambient lighting should be sufficiently good so that the texts on the label can be clearly identified where reflections should be avoided. Besides, the photo should be taken with as few unrelated backgrounds as possible. As the brightness, the contrast, or the other environmental conditions can be changed depending on time and places, the accuracy of the OCR can fluctuate significantly. 

    \subsection{Character Recognition by OCR Software}
        On the server, the label photo is input to an OCR software to recognize the characters in the photo. The accuracy of the system mainly depends on the accuracy of the character recognition results by the OCR software. Unfortunately, we cannot find the commercial OCR software that can avoid a recognition error. Therefore, we propose the following procedure to improve the product identification accuracy of the system by compensating the insufficiency of the OCR software.

    \subsection{Candidate Extraction by Regular Expression}
    \label{sec:regex}
        First, the following regular expression is applied to the recognized characters by the OCR software, to filter and extract all the alphanumeric strings from them as the candidates to the {\em product model number}:

            \begin{center}
            \begin{BVerbatim}
[ :]*((?=[a-zA-Z0-9\-\/\(\)]*[0-9])
[a-zA-Z0-9\-\/\(\)]{4,})[ ,.]*
            \end{BVerbatim}
            \end{center}
    
        The {\em [ :]*} in the beginning is set to exclude any possible guiding space or colon before the alphanumeric string we need. Then, in the long expression with the brackets, {\em ((?=[a-zA-Z0-9$\backslash$-$\backslash$/$\backslash$($\backslash$)]*[0-9])[a-zA-Z0-9$\backslash$-$\backslash$/$\backslash$($\backslash$)]\{4,\}) }, the {\em (?=[a-zA-Z0-9$\backslash$-$\backslash$/$\backslash$($\backslash$)]*[0-9])} is called for the positive look-ahead in the regular expression. It asserts that the following alphanumeric string should be ending with a number\cite{lookahead}-\cite{regex-tutorial}. This positive look-ahead indicates what the following string should appear. 

        However, it does not actually pick any string, so that the string may contain a number at the middle rather than at the end. Thus, the following {\em [a-zA-Z0-9$\backslash$-$\backslash$/$\backslash$($\backslash$)]\{4,\})} is the one that actually picks a string that has more than four characters as the length, containing letters, numbers, brackets, hyphen, or slashes, without any space. In other words, the alphanumeric string for the candidate of the {\em product model number} must have more than four characters in the length, by containing letters, numbers, brackets, hyphen, or slashes only.

        At the last of the regular expression, {\em [ ,.]*} is used to exclude any possible following space, comma, or dot after the alphanumeric string, and make sure the string ends at the correct position.

        
    \subsection{Similarity Calculation}
    \label{sec:algorithm.ocrregex}
        Next, if at least one candidate string for the product model number is extracted in the previous step, the similarity between each candidate string and every corresponding record in the database is calculated using {\em FuzzyWuzzy}. For this purpose, the database should be prepared in advance to contain the related data for any possible product to be identified by the system. Table~\ref{table:db-sample} shows a part of this database. The number of records in this database increases as the number of products to be identified by the system increases. As a result, the CPU time for the similarity calculation by {\em FuzzyWuzzy} can be inhibitory long as the user interactive system.

        \begin{table}[tb]
            \caption{Part of database records.}
            \label{table:db-sample}
            \begin{center}
                \begin{tabular}{l|l}
                    \Hline
                    product\_name & model\_number \\
                    \Hline
                    I-O DATA & EX-LD2071TB \\
                    CM 690 III & CMS-693-KKN1-JP \\
                    EVO Plus & MB-MC128GA \\
                    dynabook PC & PT45NWY-SHA \\
                    ThinkPad X1 Tablet & 20GH-A06VJP \\
                    GALAXY TAB A & SM-T510 \\
                    ThinkSystem & ST50 \\
                    au & T003 \\
                    ideapad S340-14IIL & 81VV \\
                    bizhub & 224e \\
                    COREFIDO & B820n \\
                    ThinkCentre & M900 Small \\
                    dynabook & PT45UWP-SWA \\
                    Smart-UPS 750 & SUA750JB \\
                    dynabook & AZ25/CW \\
                    dynabook Celeron HD & AZ25/B \\
                    dynabook & AZ25/CB \\
                    dynabook Celeron & AZ25/DR \\
                    dynabook Celeron & AZ25/DW  \\
                    HP EliteBook 830 G6 & 8AZ25PA\#ABJ \\
                    PageWide XL & XL 8000 \\                  
                    \Hline
                \end{tabular}
            \end{center}
        \end{table}

    \subsection{System Output}
        Finally, the system outputs all the product model numbers in the database that have the $70$ or higher similarity in descending order. Since the OCR accuracy is not high enough, the system outputs any possible candidate of the product model number, and asks the user to choose one from them manually to improve the accuracy. In most cases, the first candidate is the correct one because it has the highest similarity. Figure~\ref{fig:result-sample} shows the output to the label photo in Figure~\ref{fig:camera}. Here, seven candidates for the product model number are displayed, and the first one is correct.

        \begin{figure}[t] 
            \begin{center}
                \begin{BVerbatim}
Matched Model:
{
    "EX-LD2071TB": 100,
    "EX-LDGC271TB": 87,
    "EX-LD2071TNV": 87,
    "EX-LDQ271DB": 82,
    "EX-LDH271DB": 82,
    "100-MR140": 71,
    "100-LA024": 71
}
                \end{BVerbatim}
            \end{center}
            \caption{Sample result list of the system}
            \label{fig:result-sample}
        \end{figure}


%+++++++++++++++++++++++++++++++++++++++++++++++
\section{Proposal of Speedup Method for Fuzzy Search}
\label{sec:speedup}
    In this section, we present the speedup method for the fuzzy search using the partial word matching to avoid the long response time of the system.

    \subsection{Overview}
        In the naïve logic, the most time-consuming procedure is the {\em similarity calculation} using {\em FuzzyWuzzy}, since the similarity between the candidate strings from the OCR software and all the records in database have to be calculated. For the speedup, we limit the records in the database for the similarity calculations. Here we select every record whose part is exactly matching with part of the divided candidate string, and calculate the similarity against the selected record only.

    \subsection{Half Divided String}
        As the part of the candidate string, we use the first half and the second half of it. Thus, after the procedure of {\em Candidate Extraction by Regular Expression}, we divide each extracted candidate alphanumeric string into two halves at the center of the string.

    \subsection{Partial Word Matching}

        It has been observed that in most cases of the OCR errors, the number of incorrectly recognized characters does not exceed one.

        Thus we divide one alphanumeric string into two halves. For each half, partial matching is performed against every record in the database. Like in table \ref{table:half_matching}. We use partial matching rather than forward or backward matching so that we can avoid OCR text missing.

        In this way, for example, if the misrecognized character is in the second half, the first half is a correct recognition. Partial matching can ensure that the completely matched correct model from the master database is included in the matching result. Conversely, if the misrecognized character is in the first half, partial matching can also help us to match the correct model.
        
        Let the original label text be “AZ25/CB” and the OCR result be “AZ25/C8”, with one error. As shown in table \ref{table:half_matching}, it is divided into “AZ25” and “/C8”. The matching result will contain the correct “AZ25/CB” model and together with some other models sharing the same half with less similarity, then output all of them into the result list.

        \begin{table}[tb]
            \caption{Half divided string and its matching results}
            \label{table:half_matching}
            \begin{center}
                \begin{tabular}{c|c|c}
                \Hline
                origional label text & \multicolumn{2}{c}{AZ25/CB} \\ 
                \hline
                OCR result & \multicolumn{2}{c}{AZ25/C{\em 8}} \\ 
                \hline
                half divided strings & \_\_AZ25\_\_ & \_\_/C{\em 8}\_\_ \\
                \hline
                matching results & \begin{tabular}{c}AZ25\underline{/CB}\\AZ25\underline{/B}\\AZ25\underline{/CW}\\\underline{8}AZ25\underline{PA\#ABJ}\\...\end{tabular} & (no result) \\
                \Hline
                \end{tabular}
            \end{center}
        \end{table}
        
%+++++++++++++++++++++++++++++++++++++++++++++++
\section{Evaluation}
\label{sec:evaluation}
    In this section, we evaluate the proposed system. For evaluations, we collected 396 photos of different products using the system.

    \subsection{Strings Extracted by Regular Expression}

        \begin{figure}[t] 
            \begin{center}
            \includegraphics[width=0.48\textwidth]{figure/label-regex-samp.png}
            \end{center}
            \caption{Product label photo used to test regular expression.}
            \label{fig:label-regex-samp}
        \end{figure}

        \begin{figure}[t] 
            \begin{center}
                \begin{BVerbatim}[commandchars=\\\{\}]
NEC
AC ADAPTOR \textcolor{red}{ADP64}
\textcolor{red}{PC-VP-WP36-01/OP-520-75601-01}
\textcolor{red}{ANEC-Y7097Y} N)(S) (D) (FI
D FI
KETI \textcolor{red}{HU10104-2008}
INPUT: AC \textcolor{red}{100-240V 50-60} Hz \textcolor{red}{130-195VA}
OUTPUT: DC 19V 3.16A
S/N(IF ): \textcolor{red}{7919595DA}
MODEL ( O:\textcolor{red}{ADP-60NH}
INPUT (A)(MA):100-\textcolor{red}{240V}~ 1.5A \textcolor{red}{50-60HZ} S
OUTPUT()():19V==3.16A ODO
\textcolor{red}{ADP-60NH}
MARK
NEC Personal Products, Ltd. 0 2 0 85 6 -0 0
                \end{BVerbatim}
            \end{center}
            \caption{An example of regular expression matching result}
            \label{fig:result-regex}
        \end{figure}

        As shown in figure \ref{fig:result-regex}, we use a tool called regex101\cite{regex101}, to test our regular expression described in section \ref{sec:regex} with some text extracted by OCR of a label photo shown in Figure~\ref{fig:label-regex-samp}. The red strings are the alphanumeric strings matched, and will be exported as candidates. We can see that the correct model {\em ADP-60NH} is among the matched part. Although the same string is matched multiple times, we will remove the duplicate ones.

    \subsection{Regular Expression Matching Rate}
    \label{sec:regex-result}

        We then used the regular expression on the OCR texts from all the $396$ photos.

        \begin{table*}[t]
            \caption{Regular expression matching result}
            \label{table:regex_result}
            \begin{center}
                \begin{tabular}{c|cccc}
                \Hline
                    Extraction result & \begin{tabular}{c}Model extracted \\ exactly correct\end{tabular} & \begin{tabular}{c}Model extracted \\ partially correct\end{tabular} & \begin{tabular}{c}Model \\ not extracted\end{tabular} & Total \\ 
                \hline
                Count & 311 & 78 & 7 & 396 \\
                Percentage (\%) & 78.5 & 19.7 & 1.8 & 100.0 \\
                Average count of strings extracted for one item & 8.39 & 10.13 & 3.86 & 8.65 \\ 
                % \hline
                Maximum count of strings extracted for one item & 38 & 23 & 8 & 38 \\ 
                % \hline
                Mininum count of strings extracted for one item & 1 & 1 & 2 & 1 \\ 
                \Hline
                \end{tabular}
            \end{center}
        \end{table*}

        As shown in table \ref{table:regex_result}, among all the $396$ tests, in $311$ cases the alphanumeric string containing correct model is successfully extracted by our regular expression. The correct extracting rate is about $78.5\%$.
        
        In $19.7\%$ cases, the extracted strings are partially correct, with slightly errors caused by OCR. In these cases, the OCR error could be tolerated by later fuzzy search.
        
        There are still $1.8\%$ cases in which our regular expression failed to match the correct model. These cases are mostly caused by too-short model numbers.
        
        The average amount of strings extracted for one item is $8.65$. All these results will be used as keywords in later fuzzy search. The minimum amount of strings extracted for one item is $1$, while the maximum is $38$.



    \subsection{Speed-up Method for Fuzzy Search Process}
            
        Using the $389$ correct results from the regular expression, we conducted fuzzy search in a master database with $553887$ records using both the naïve method and the speed-up method. The results are shown in table~\ref{table:methods_compare}.

        \begin{table*}[t]
            \caption{Performance result using different searching methods}
            \label{table:methods_compare}
            \begin{center}
                \begin{tabular}{l|ccc|ccc}
                \Hline
                Searching method &
                    \multicolumn{3}{c}{Naïve method} &
                    \multicolumn{3}{c}{Speed-up method} \\ 
                \hline
                Regular expression result &
                    Exact match & Partial match & Total & 
                    Exact match & Partial match & Total \\ 
                \hline
                Total count &
                    311 & 78 & 389 &
                    311 & 78 & 389 \\
                Max similarity score in candidates &
                    100 & 100 & 100 &
                    100 & 100 & 100 \\ 
                Correct model is max score candidate &
                    307 & 33 & 340 &
                    307 & 32 & 339 \\ 
                Correct model in other candidates &
                    4 & 23 & 27 &
                    4 & 23 & 27 \\ 
                Correct model not in candidates &
                    0 & 22 & 22 &
                    0 & 23 & 23 \\ 
                Recognition rate (\%) &
                    100.0 & 71.8 & 94.3 &
                    100.0 & 70.5 & 94.1 \\ 
                Average candidate count &
                    14.56 & 14.79 & 14.60 &
                    12.64 & 12.58 & 12.63 \\ 
                Average search time (sec) &
                    14.82 & 17.68 & 15.39 &
                    0.98 & 1.03 & 0.99 \\ 
                Mininum search time (sec) &
                    2.04 & 2.07 & 2.04 &
                    0.54 & 0.51 & 0.51 \\ 
                Maximum search time (sec) &
                    64.27 & 39.54 & 64.27 &
                    3.00 & 2.51 & 3.00 \\ 
                Average search range (DB record amount) &
                    553887.00 & 553887.00 & 553887.00 &
                    1208.27 & 1916.88 & 1350.36 \\
                \Hline
                \end{tabular}
            \end{center}
        \end{table*}

        Using naïve method, there are $340$ cases in which the candidate with the high similarity score is the correct one. In these cases users do not need to choose the correct candidate. There are $14.60$ candidates on average for one search. In $94.3\%$ cases the correct models are among the candidates. The average searching time for each item is $15.39sec$, while the maximum is $64.27sec$. As for each item we look up all the records in master DB, the average search range is the amount of records in DB: $553887$.
        
        Using speed-up method, there are $339$ cases in which the candidate with the high similarity score is the correct one. There are $12.63$ candidates on average for one search. In $94.1\%$ cases the correct models are among the candidates, which is slightly lower than using naïve method. The average searching time for each item is $0.99sec$, while the maximum is $3.00sec$. The average search range for each item is $1350.36$, which means the amount of DB record we looked up in fuzzy search.

        We found that both methods behave well on searching with {\em exactly correct exported regular expression results}. For {\em partially correct exported regular expression results}, both methods successfully corretced over $70\%$ of misrecognized OCR texts.

        Using the speed-up method can effectively reduce the time into the acceptable range while increasing the accuracy rate to be close to that of the naïve method. With this method, we can take a balance between searching speed and mistake prevention for OCR text, and successfully limit the search range to about $0.24\%$ of all data amount. The search result would come out in less than $1sec$ on average, which is acceptable for users to wait.
        
        As shown from the result, our speed-up method for fuzzy search is proved to be effective.

        
        \begin{table*}[t]
            \caption{Some slow searching using speed-up method}
            \label{table:slowest_rec}
            \begin{center}
                \begin{tabular}{c|c|c|c|c|c|c}
                \Hline
                    Model &
                    \begin{tabular}{c}Reuglar\\expression\\matching results\end{tabular} &
                    \begin{tabular}{c}Search\\time (s)\end{tabular} &
                    \begin{tabular}{c}Search range\\(DB record\\amount)\end{tabular} &
                    \begin{tabular}{c}Correct model\\is max score\\ candidate\end{tabular} &
                    \begin{tabular}{c}Correct model\\in other\\candidates\end{tabular} &
                    \begin{tabular}{c}Max similarity\\score in\\candidates\end{tabular} \\ 
                \Hline
                DC35 & 14 & 1.80353 & 24675 & False & False & 89 \\ 
                \hline
                DM-E25AW & 29 & 2.41260 & 2912 & True & True & 100 \\ 
                \hline
                TPC-F026-SF & 23 & 2.51139 & 6761 & True & True & 91 \\ 
                \hline
                K04A-WH & 38 & 2.53164 & 5009 & True & True & 100 \\ 
                \hline
                MRO-GS8 & 22 & 2.91033 & 3822 & True & True & 100 \\ 
                \hline
                NE-BS805-K & 33 & 3.00420 & 5574 & True & True & 100 \\ 
                \Hline
                \end{tabular}
            \end{center}
        \end{table*}
      
        It can be seen from table~\ref{table:slowest_rec} that for few cases, even by using speed-up method, the search range can still be large, thus it took longer than average time and not as fast as expected. The longest searching time of over $3$ seconds. This indicates that we can still do more to further improve the speed.
               
%+++++++++++++++++++++++++++++++++++++++++++++++
\section{Conclusion}
\label{sec:conclusion}
    In this section, we conclude this study with future works.

    In this study, we proposed the {\em product identification system} using OCR of the label photo by a smart phone. The {\em fuzzy search} is adopted with the speedup method to improve the accuracy by finding the best-matching record in the database. The application results to $396$ label photos showed the effectiveness of the proposal. In future works, we will improve the user interface and further investigate the performance of the proposal with various product label photos.

    As mentioned in section~\ref{sec:regex-result}, all the extracted strings by the regular expression are used as keywords in fuzzy search. But we can find out that in most cases the model number is exactly exported by the regular expression, and do not need futher correction or be tolerated by fuzzy search. So in the future, after doing partial matching for both halves of exported strings, we can compare the results between them. If one model number is matched by both halves, that means the string could be exactly the model number, and can be outputed as the result, no more similarity calculation is needed. This may make the whole process even more faster.
            
    We consider that, for each record in the master database, we can add not only the model text information of the product, but also its brand or manufacturer information. Before doing fuzzy search, we can also use other recognition methods to match and analyze the text contained in the OCR results to determine the brand of the product, and use brand information matching to further limit the search range of fuzzy search for model texts, which may further improve searching performance.

    Also, for the result of regular expression shown in figure \ref{fig:result-regex}, we can see some alphanumeric strings unrelated with model also got matched. In future studies we need to find better patterns for regular expression to reduce unnecessary fuzzy searching.

    As our output is a list of most possible models in the product label, it is possible that there are several similar models with the same matching rate. How to correctly pick out the correct one is still to be studied.


%+++++++++++++++++++++++++++++++++++++++++++++++
%\bibliographystyle{sieicej}
%\bibliography{myrefs}
\begin{thebibliography}{99}% 文献数が10未満の時 {9}
    \bibitem{fuzzywuzzy-guidence}
    T., B. (2020, November 14). \emph{FuzzyWuzzy: Fuzzy String Matching in Python, Beginner’s Guide.} Towards Data Science. \url{https://towardsdatascience.com/fuzzywuzzy-fuzzy-string-matching-in-python-beginners-guide-9adc0edf4b35}

    \bibitem{string-correction}
    Wagner, R. A., \& Fischer, M. J. (1974). The String-to-String Correction Problem. \emph{Journal of the ACM, 21(1)}, 168–173. \url{https://doi.org/10.1145/321796.321811}

    \bibitem{guide-to-matching}
    Navarro, G. (2001). A guided tour to approximate string matching. \emph{ACM Computing Surveys, 33(1)}, 31–88. \url{https://doi.org/10.1145/375360.375365}

    \bibitem{levenshtein}
    Wikipedia contributors. (2020, December 15). \emph{Levenshtein distance.} Wikipedia. \url{https://en.wikipedia.org/wiki/Levenshtein_distance}

    \bibitem{fuzzywuzzy}
    Cohen, A. (2011, July 8). \emph{FuzzyWuzzy: Fuzzy String Matching in Python.} ChairNerd. \url{https://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/}

    \bibitem{fuzzywuzzy-git}
    Seatgeek. (2020, February 14). \emph{FuzzyWuzzy.} GitHub. \url{https://github.com/seatgeek/fuzzywuzzy}

    \bibitem{lookahead}
    Goyvaerts, J. (2020, March 9). \emph{Positive and Negative Lookahead.} Regular-Expressions.info. \url{https://www.regular-expressions.info/lookaround.html}

    \bibitem{lookahead-and-behind}
    BoppreH, hwnd, Trzesniewski, L., Stribiżew, W., \& Ivanova, M.(n.d.). \emph{Regular Expressions - Lookahead and Lookbehind.} SO Documentation. Retrieved December 23, 2020, from \url{https://sodocumentation.net/regex/topic/639/lookahead-and-lookbehind}

    \bibitem{regex-tutorial}
    RegexTutorial.org. (n.d.). \emph{Positive \& Negative Lookahead.} Regex Tutorial. Retrieved December 14, 2020, from \url{https://www.regextutorial.org/positive-and-negative-lookahead-assertions.php}

    \bibitem{regex101}
    Dib, F. (2017, March 31). \emph{Online regex tester and debugger.} Regex101. \url{https://regex101.com/}

\end{thebibliography}

\end{document}


